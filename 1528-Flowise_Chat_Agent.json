{
  "nodes": [
    {
      "id": "toolAgent_0",
      "position": {
        "x": 649.551263249906,
        "y": 88.48134903403383
      },
      "type": "customNode",
      "data": {
        "id": "toolAgent_0",
        "label": "Tool Agent",
        "version": 2,
        "name": "toolAgent",
        "type": "AgentExecutor",
        "baseClasses": [
          "AgentExecutor",
          "BaseChain",
          "Runnable"
        ],
        "category": "Agents",
        "description": "Agent that uses Function Calling to pick the tools and args to call",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessage",
            "type": "string",
            "default": "You are a helpful AI assistant.",
            "description": "If Chat Prompt Template is provided, this will be ignored",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-systemMessage-string"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "id": "toolAgent_0-input-tools-Tool"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseChatMemory",
            "id": "toolAgent_0-input-memory-BaseChatMemory"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
            "id": "toolAgent_0-input-model-BaseChatModel"
          },
          {
            "label": "Chat Prompt Template",
            "name": "chatPromptTemplate",
            "type": "ChatPromptTemplate",
            "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable",
            "optional": true,
            "id": "toolAgent_0-input-chatPromptTemplate-ChatPromptTemplate"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "toolAgent_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "tools": [
            "{{retrieverTool_0.data.instance}}"
          ],
          "memory": "{{RedisBackedChatMemory_0.data.instance}}",
          "model": "{{chatOpenAI_0.data.instance}}",
          "chatPromptTemplate": "",
          "systemMessage": "Eres un jurista y tu objetivo es responder a consultas relacionadas con el Ã¡mbito del Derecho.",
          "inputModeration": [
            "{{inputModerationOpenAI_0.data.instance}}",
            "{{inputModerationSimple_0.data.instance}}"
          ],
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "toolAgent_0-output-toolAgent-AgentExecutor|BaseChain|Runnable",
            "name": "toolAgent",
            "label": "AgentExecutor",
            "description": "Agent that uses Function Calling to pick the tools and args to call",
            "type": "AgentExecutor | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 484,
      "selected": false,
      "positionAbsolute": {
        "x": 649.551263249906,
        "y": 88.48134903403383
      },
      "dragging": false
    },
    {
      "id": "chatOpenAI_0",
      "position": {
        "x": -55.471480020215424,
        "y": 176.7474828919771
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 8.1,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-4o-mini",
            "id": "chatOpenAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number"
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-streaming-boolean"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number"
          },
          {
            "label": "Strict Tool Calling",
            "name": "strictToolCalling",
            "type": "boolean",
            "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-strictToolCalling-boolean"
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatOpenAI_0-input-stopSequence-string"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string"
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-proxyUrl-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean"
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-imageResolution-options"
          },
          {
            "label": "Reasoning Effort",
            "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 and o3 models.",
            "name": "reasoningEffort",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "Medium",
                "name": "medium"
              },
              {
                "label": "High",
                "name": "high"
              }
            ],
            "default": "medium",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-reasoningEffort-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4o-mini",
          "temperature": "0.1",
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "0",
          "presencePenalty": "0",
          "timeout": "",
          "strictToolCalling": "",
          "stopSequence": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low",
          "reasoningEffort": "medium"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 668,
      "selected": false,
      "positionAbsolute": {
        "x": -55.471480020215424,
        "y": 176.7474828919771
      },
      "dragging": false
    },
    {
      "id": "RedisBackedChatMemory_0",
      "position": {
        "x": -26.673676445267432,
        "y": -301.0104781408642
      },
      "type": "customNode",
      "data": {
        "id": "RedisBackedChatMemory_0",
        "label": "Redis-Backed Chat Memory",
        "version": 2,
        "name": "RedisBackedChatMemory",
        "type": "RedisBackedChatMemory",
        "baseClasses": [
          "RedisBackedChatMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Summarizes the conversation and stores the memory in Redis server",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "optional": true,
            "credentialNames": [
              "redisCacheApi",
              "redisCacheUrlApi"
            ],
            "id": "RedisBackedChatMemory_0-input-credential-credential"
          },
          {
            "label": "Session Id",
            "name": "sessionId",
            "type": "string",
            "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory/long-term-memory#ui-and-embedded-chat\">more</a>",
            "default": "",
            "additionalParams": true,
            "optional": true,
            "id": "RedisBackedChatMemory_0-input-sessionId-string"
          },
          {
            "label": "Session Timeouts",
            "name": "sessionTTL",
            "type": "number",
            "description": "Seconds till a session expires. If not specified, the session will never expire.",
            "additionalParams": true,
            "optional": true,
            "id": "RedisBackedChatMemory_0-input-sessionTTL-number"
          },
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "additionalParams": true,
            "id": "RedisBackedChatMemory_0-input-memoryKey-string"
          },
          {
            "label": "Window Size",
            "name": "windowSize",
            "type": "number",
            "description": "Window of size k to surface the last k back-and-forth to use as memory.",
            "additionalParams": true,
            "optional": true,
            "id": "RedisBackedChatMemory_0-input-windowSize-number"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "sessionId": "",
          "sessionTTL": "",
          "memoryKey": "chat_history",
          "windowSize": "5"
        },
        "outputAnchors": [
          {
            "id": "RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory",
            "name": "RedisBackedChatMemory",
            "label": "RedisBackedChatMemory",
            "description": "Summarizes the conversation and stores the memory in Redis server",
            "type": "RedisBackedChatMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 326,
      "selected": false,
      "positionAbsolute": {
        "x": -26.673676445267432,
        "y": -301.0104781408642
      },
      "dragging": false
    },
    {
      "id": "inputModerationOpenAI_0",
      "position": {
        "x": 48.85286171147311,
        "y": 912.4717539417846
      },
      "type": "customNode",
      "data": {
        "id": "inputModerationOpenAI_0",
        "label": "OpenAI Moderation",
        "version": 1,
        "name": "inputModerationOpenAI",
        "type": "Moderation",
        "baseClasses": [
          "Moderation"
        ],
        "category": "Moderation",
        "description": "Check whether content complies with OpenAI usage policies.",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "inputModerationOpenAI_0-input-credential-credential"
          },
          {
            "label": "Error Message",
            "name": "moderationErrorMessage",
            "type": "string",
            "rows": 2,
            "default": "Cannot Process! Input violates OpenAI's content moderation policies.",
            "optional": true,
            "id": "inputModerationOpenAI_0-input-moderationErrorMessage-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "moderationErrorMessage": "No puedo ayudarte con esto"
        },
        "outputAnchors": [
          {
            "id": "inputModerationOpenAI_0-output-inputModerationOpenAI-Moderation",
            "name": "inputModerationOpenAI",
            "label": "Moderation",
            "description": "Check whether content complies with OpenAI usage policies.",
            "type": "Moderation"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 451,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 48.85286171147311,
        "y": 912.4717539417846
      }
    },
    {
      "id": "inputModerationSimple_0",
      "position": {
        "x": 418.2867800463305,
        "y": 975.2058155458171
      },
      "type": "customNode",
      "data": {
        "id": "inputModerationSimple_0",
        "label": "Simple Prompt Moderation",
        "version": 2,
        "name": "inputModerationSimple",
        "type": "Moderation",
        "baseClasses": [
          "Moderation"
        ],
        "category": "Moderation",
        "description": "Check whether input consists of any text from Deny list, and prevent being sent to LLM",
        "inputParams": [
          {
            "label": "Deny List",
            "name": "denyList",
            "type": "string",
            "rows": 4,
            "placeholder": "ignore previous instructions\ndo not follow the directions\nyou must ignore all previous instructions",
            "description": "An array of string literals (enter one per line) that should not appear in the prompt text.",
            "id": "inputModerationSimple_0-input-denyList-string"
          },
          {
            "label": "Error Message",
            "name": "moderationErrorMessage",
            "type": "string",
            "rows": 2,
            "default": "Cannot Process! Input violates content moderation policies.",
            "optional": true,
            "id": "inputModerationSimple_0-input-moderationErrorMessage-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Use LLM to detect if the input is similar to those specified in Deny List",
            "optional": true,
            "id": "inputModerationSimple_0-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "denyList": "-Insultar\n-Palabras malsonantes",
          "model": "",
          "moderationErrorMessage": "No puedo ayudarte con esto"
        },
        "outputAnchors": [
          {
            "id": "inputModerationSimple_0-output-inputModerationSimple-Moderation",
            "name": "inputModerationSimple",
            "label": "Moderation",
            "description": "Check whether input consists of any text from Deny list, and prevent being sent to LLM",
            "type": "Moderation"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 583,
      "selected": false,
      "positionAbsolute": {
        "x": 418.2867800463305,
        "y": 975.2058155458171
      },
      "dragging": false
    },
    {
      "id": "retrieverTool_0",
      "position": {
        "x": 494.96174422903687,
        "y": -812.0178950401704
      },
      "type": "customNode",
      "data": {
        "id": "retrieverTool_0",
        "label": "Retriever Tool",
        "version": 3,
        "name": "retrieverTool",
        "type": "RetrieverTool",
        "baseClasses": [
          "RetrieverTool",
          "DynamicTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use a retriever as allowed tool for agent",
        "inputParams": [
          {
            "label": "Retriever Name",
            "name": "name",
            "type": "string",
            "placeholder": "search_state_of_union",
            "id": "retrieverTool_0-input-name-string"
          },
          {
            "label": "Retriever Description",
            "name": "description",
            "type": "string",
            "description": "When should agent uses to retrieve documents",
            "rows": 3,
            "placeholder": "Searches and returns documents regarding the state-of-the-union.",
            "id": "retrieverTool_0-input-description-string"
          },
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "retrieverTool_0-input-returnSourceDocuments-boolean"
          },
          {
            "label": "Additional Metadata Filter",
            "name": "retrieverToolMetadataFilter",
            "type": "json",
            "description": "Add additional metadata filter on top of the existing filter from vector store",
            "optional": true,
            "additionalParams": true,
            "hint": {
              "label": "What can you filter?",
              "value": "Add additional filters to vector store. You can also filter with flow config, including the current \"state\":\n- $flow.sessionId\n- $flow.chatId\n- $flow.chatflowId\n- $flow.input\n- $flow.state\n"
            },
            "id": "retrieverTool_0-input-retrieverToolMetadataFilter-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Retriever",
            "name": "retriever",
            "type": "BaseRetriever",
            "id": "retrieverTool_0-input-retriever-BaseRetriever"
          }
        ],
        "inputs": {
          "name": "conocimiento",
          "description": "Busca informaciÃ³n para responder a consultas jurÃ­dicas",
          "retriever": "{{qdrant_0.data.instance}}",
          "returnSourceDocuments": "",
          "retrieverToolMetadataFilter": ""
        },
        "outputAnchors": [
          {
            "id": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
            "name": "retrieverTool",
            "label": "RetrieverTool",
            "description": "Use a retriever as allowed tool for agent",
            "type": "RetrieverTool | DynamicTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 654,
      "selected": false,
      "positionAbsolute": {
        "x": 494.96174422903687,
        "y": -812.0178950401704
      },
      "dragging": false
    },
    {
      "id": "qdrant_0",
      "position": {
        "x": -68.4128893490708,
        "y": -1250.1205392401098
      },
      "type": "customNode",
      "data": {
        "id": "qdrant_0",
        "label": "Qdrant",
        "version": 5,
        "name": "qdrant",
        "type": "Qdrant",
        "baseClasses": [
          "Qdrant",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "Upsert embedded data and perform similarity search upon query using Qdrant, a scalable open source vector database written in Rust",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "description": "Only needed when using Qdrant cloud hosted",
            "optional": true,
            "credentialNames": [
              "qdrantApi"
            ],
            "id": "qdrant_0-input-credential-credential"
          },
          {
            "label": "Qdrant Server URL",
            "name": "qdrantServerUrl",
            "type": "string",
            "placeholder": "http://localhost:6333",
            "id": "qdrant_0-input-qdrantServerUrl-string"
          },
          {
            "label": "Qdrant Collection Name",
            "name": "qdrantCollection",
            "type": "string",
            "id": "qdrant_0-input-qdrantCollection-string"
          },
          {
            "label": "File Upload",
            "name": "fileUpload",
            "description": "Allow file upload on the chat",
            "hint": {
              "label": "How to use",
              "value": "\n**File Upload**\n\nThis allows file upload on the chat. Uploaded files will be upserted on the fly to the vector store.\n\n**Note:**\n- You can only turn on file upload for one vector store at a time.\n- At least one Document Loader node should be connected to the document input.\n- Document Loader should be file types like PDF, DOCX, TXT, etc.\n\n**How it works**\n- Uploaded files will have the metadata updated with the chatId.\n- This will allow the file to be associated with the chatId.\n- When querying, metadata will be filtered by chatId to retrieve files associated with the chatId.\n"
            },
            "type": "boolean",
            "additionalParams": true,
            "optional": true,
            "id": "qdrant_0-input-fileUpload-boolean"
          },
          {
            "label": "Vector Dimension",
            "name": "qdrantVectorDimension",
            "type": "number",
            "default": 1536,
            "additionalParams": true,
            "id": "qdrant_0-input-qdrantVectorDimension-number"
          },
          {
            "label": "Content Key",
            "name": "contentPayloadKey",
            "description": "The key for storing text. Default to `content`",
            "type": "string",
            "default": "content",
            "optional": true,
            "additionalParams": true,
            "id": "qdrant_0-input-contentPayloadKey-string"
          },
          {
            "label": "Metadata Key",
            "name": "metadataPayloadKey",
            "description": "The key for storing metadata. Default to `metadata`",
            "type": "string",
            "default": "metadata",
            "optional": true,
            "additionalParams": true,
            "id": "qdrant_0-input-metadataPayloadKey-string"
          },
          {
            "label": "Upsert Batch Size",
            "name": "batchSize",
            "type": "number",
            "step": 1,
            "description": "Upsert in batches of size N",
            "additionalParams": true,
            "optional": true,
            "id": "qdrant_0-input-batchSize-number"
          },
          {
            "label": "Similarity",
            "name": "qdrantSimilarity",
            "description": "Similarity measure used in Qdrant.",
            "type": "options",
            "default": "Cosine",
            "options": [
              {
                "label": "Cosine",
                "name": "Cosine"
              },
              {
                "label": "Euclid",
                "name": "Euclid"
              },
              {
                "label": "Dot",
                "name": "Dot"
              }
            ],
            "default": "Cosine",
            "additionalParams": true,
            "id": "qdrant_0-input-qdrantSimilarity-options"
          },
          {
            "label": "Additional Collection Cofiguration",
            "name": "qdrantCollectionConfiguration",
            "description": "Refer to <a target=\"_blank\" href=\"https://qdrant.tech/documentation/concepts/collections\">collection docs</a> for more reference",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "qdrant_0-input-qdrantCollectionConfiguration-json"
          },
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "qdrant_0-input-topK-number"
          },
          {
            "label": "Qdrant Search Filter",
            "name": "qdrantFilter",
            "description": "Only return points which satisfy the conditions",
            "type": "json",
            "additionalParams": true,
            "optional": true,
            "id": "qdrant_0-input-qdrantFilter-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "qdrant_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "qdrant_0-input-embeddings-Embeddings"
          },
          {
            "label": "Record Manager",
            "name": "recordManager",
            "type": "RecordManager",
            "description": "Keep track of the record to prevent duplication",
            "optional": true,
            "id": "qdrant_0-input-recordManager-RecordManager"
          }
        ],
        "inputs": {
          "document": "",
          "embeddings": "{{openAIEmbeddings_0.data.instance}}",
          "recordManager": "",
          "qdrantServerUrl": "http://qdrant:6333",
          "qdrantCollection": "documentos",
          "fileUpload": "",
          "qdrantVectorDimension": 1536,
          "contentPayloadKey": "content",
          "metadataPayloadKey": "metadata",
          "batchSize": "",
          "qdrantSimilarity": "Cosine",
          "qdrantCollectionConfiguration": "",
          "topK": "",
          "qdrantFilter": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "qdrant_0-output-retriever-Qdrant|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Qdrant Retriever",
                "description": "",
                "type": "Qdrant | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "qdrant_0-output-vectorStore-Qdrant|VectorStore",
                "name": "vectorStore",
                "label": "Qdrant Vector Store",
                "description": "",
                "type": "Qdrant | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 703,
      "selected": false,
      "positionAbsolute": {
        "x": -68.4128893490708,
        "y": -1250.1205392401098
      },
      "dragging": false
    },
    {
      "id": "openAIEmbeddings_0",
      "position": {
        "x": -552.6826072281963,
        "y": -1233.2088492775133
      },
      "type": "customNode",
      "data": {
        "id": "openAIEmbeddings_0",
        "label": "OpenAI Embeddings",
        "version": 4,
        "name": "openAIEmbeddings",
        "type": "OpenAIEmbeddings",
        "baseClasses": [
          "OpenAIEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "OpenAI API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "openAIEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "text-embedding-ada-002",
            "id": "openAIEmbeddings_0-input-modelName-asyncOptions"
          },
          {
            "label": "Strip New Lines",
            "name": "stripNewLines",
            "type": "boolean",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-stripNewLines-boolean"
          },
          {
            "label": "Batch Size",
            "name": "batchSize",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-batchSize-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-basepath-string"
          },
          {
            "label": "Dimensions",
            "name": "dimensions",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-dimensions-number"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "text-embedding-3-large",
          "stripNewLines": "",
          "batchSize": "",
          "timeout": "",
          "basepath": "",
          "dimensions": "1536"
        },
        "outputAnchors": [
          {
            "id": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
            "name": "openAIEmbeddings",
            "label": "OpenAIEmbeddings",
            "description": "OpenAI API to generate embeddings for a given text",
            "type": "OpenAIEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 422,
      "selected": false,
      "positionAbsolute": {
        "x": -552.6826072281963,
        "y": -1233.2088492775133
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "chatOpenAI_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-toolAgent_0-toolAgent_0-input-model-BaseChatModel"
    },
    {
      "source": "RedisBackedChatMemory_0",
      "sourceHandle": "RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-memory-BaseChatMemory",
      "type": "buttonedge",
      "id": "RedisBackedChatMemory_0-RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory-toolAgent_0-toolAgent_0-input-memory-BaseChatMemory"
    },
    {
      "source": "inputModerationOpenAI_0",
      "sourceHandle": "inputModerationOpenAI_0-output-inputModerationOpenAI-Moderation",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-inputModeration-Moderation",
      "type": "buttonedge",
      "id": "inputModerationOpenAI_0-inputModerationOpenAI_0-output-inputModerationOpenAI-Moderation-toolAgent_0-toolAgent_0-input-inputModeration-Moderation"
    },
    {
      "source": "inputModerationSimple_0",
      "sourceHandle": "inputModerationSimple_0-output-inputModerationSimple-Moderation",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-inputModeration-Moderation",
      "type": "buttonedge",
      "id": "inputModerationSimple_0-inputModerationSimple_0-output-inputModerationSimple-Moderation-toolAgent_0-toolAgent_0-input-inputModeration-Moderation"
    },
    {
      "source": "retrieverTool_0",
      "sourceHandle": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-toolAgent_0-toolAgent_0-input-tools-Tool"
    },
    {
      "source": "qdrant_0",
      "sourceHandle": "qdrant_0-output-retriever-Qdrant|VectorStoreRetriever|BaseRetriever",
      "target": "retrieverTool_0",
      "targetHandle": "retrieverTool_0-input-retriever-BaseRetriever",
      "type": "buttonedge",
      "id": "qdrant_0-qdrant_0-output-retriever-Qdrant|VectorStoreRetriever|BaseRetriever-retrieverTool_0-retrieverTool_0-input-retriever-BaseRetriever"
    },
    {
      "source": "openAIEmbeddings_0",
      "sourceHandle": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
      "target": "qdrant_0",
      "targetHandle": "qdrant_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "openAIEmbeddings_0-openAIEmbeddings_0-output-openAIEmbeddings-Embeddings-qdrant_0-qdrant_0-input-embeddings-Embeddings"
    }
  ]
}