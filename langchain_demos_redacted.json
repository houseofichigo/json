{
  "name": "langchain-demos",
  "nodes": [
    {
      "parameters": {
        "options": {
          "allowFileUploads": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [
        1920,
        -80
      ],
      "id": "179170b0-0905-4df1-9c69-429fb6b4c0dd",
      "name": "When chat message received",
      "webhookId": "1cb78679-1d7c-460e-b000-e0f3201f408e"
    },
    {
      "parameters": {
        "code": {
          "execute": {
            "code": "// Get user input\nconst userMessage = $json.chatInput || $json.message || $json.content || \"Hi\";\nconst sessionId = $json.sessionId || \"default-session\";\nconsole.log(\"Processing message:\", userMessage);\n\n// Get LLM - it returns an array, so get the first element\nconst llmArray = await this.getInputConnectionData('ai_languageModel', 0);\nconst llm = llmArray[0]; // This is the actual LLM object\n\n// Get Memory - it returns an array, so get the first element\nconst memoryArray = await this.getInputConnectionData('ai_memory', 0);\nconst memory = memoryArray[0]; // This is the actual Memory object\n\n// Get Tool (web_search) - it returns an array, so get the first element\nconst toolArray = await this.getInputConnectionData('ai_tool', 0);\nconst webSearchTool = toolArray[0]; // This is the actual Tool object\n\nconsole.log(\"LLM, Memory, and Web Search Tool extracted successfully\");\n\n// Create an LLM with tools bound to it\nconst llmWithTools = llm.bindTools([webSearchTool]);\n\n// Create a system prompt that instructs the LLM when to use web search\nconst { PromptTemplate } = require('@langchain/core/prompts');\nconst prompt = PromptTemplate.fromTemplate(`You are a helpful AI assistant with access to web search. \n\nIMPORTANT: When the user asks about current information like weather, news, stock prices, or anything that requires real-time data, you MUST use the web_search tool.\n\nUser: {input}`);\n\n// Create chain with prompt and LLM with tools\nconst { RunnableSequence } = require('@langchain/core/runnables');\nconst chain = RunnableSequence.from([\n  prompt,\n  llmWithTools,\n]);\n\n// Invoke the chain\nconst result = await chain.invoke({ input: userMessage });\n\nconsole.log(\"LLM result:\", result);\nconsole.log(\"Tool calls:\", result.tool_calls);\n\n// Handle tool calls if they exist\nlet finalResponse;\nif (result.tool_calls && result.tool_calls.length > 0) {\n  console.log(\"Tool calls detected:\", result.tool_calls);\n  \n  // Execute tool calls and collect results\n  const toolMessages = [];\n  for (const toolCall of result.tool_calls) {\n    console.log(\"Executing tool:\", toolCall.name, \"with args:\", toolCall.args);\n    \n    try {\n      const toolResult = await webSearchTool.invoke(toolCall.args);\n      console.log(\"Raw tool result:\", toolResult);\n      \n      // Extract the actual content from the tool result\n      let searchContent = \"\";\n      if (typeof toolResult === 'string') {\n        searchContent = toolResult;\n      } else if (toolResult && toolResult.content) {\n        searchContent = toolResult.content;\n      } else if (toolResult && typeof toolResult === 'object') {\n        searchContent = JSON.stringify(toolResult);\n      }\n      \n      toolMessages.push({\n        role: \"tool\",\n        content: searchContent,\n        tool_call_id: toolCall.id\n      });\n      \n    } catch (error) {\n      console.log(\"Tool execution error:\", error);\n      toolMessages.push({\n        role: \"tool\", \n        content: `Error executing search: ${error.message}`,\n        tool_call_id: toolCall.id\n      });\n    }\n  }\n  \n  // Create follow-up prompt with search results\n  const followUpMessages = [\n    { role: \"user\", content: userMessage },\n    { role: \"assistant\", content: result.content, tool_calls: result.tool_calls },\n    ...toolMessages\n  ];\n  \n  console.log(\"Follow-up messages:\", followUpMessages);\n  \n  // Get final response with search results\n  const finalResult = await llm.invoke(followUpMessages);\n  finalResponse = finalResult;\n  \n} else {\n  console.log(\"No tool calls made\");\n  finalResponse = result;\n}\n\n// Manually save to memory after getting the response\ntry {\n  await memory.saveContext(\n    { input: userMessage }, \n    { output: finalResponse.content || finalResponse }\n  );\n  console.log(\"Conversation saved to memory\");\n} catch (error) {\n  console.log(\"Memory save error:\", error);\n}\n\nconsole.log(\"Final AI Response:\", finalResponse);\n\n// Return response\nreturn [{ json: { response: finalResponse.content || finalResponse, sessionId: sessionId } }];"
          }
        },
        "inputs": {
          "input": [
            {
              "type": "main"
            },
            {
              "type": "ai_languageModel"
            },
            {
              "type": "ai_memory"
            },
            {
              "type": "ai_tool"
            }
          ]
        },
        "outputs": {
          "output": [
            {
              "type": "main"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.code",
      "typeVersion": 1,
      "position": [
        600,
        -60
      ],
      "id": "e489c69d-e30e-4ed0-af5a-5ec423a571ca",
      "name": "LangChain Code"
    },
    {
      "parameters": {
        "content": "## Standard Chat Agent\nJust replicated a standard agent here. Has an AI brain, Memory, and can use tools.\n",
        "height": 120,
        "width": 300,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        560,
        -220
      ],
      "id": "ded143bd-72b9-4b99-a53a-e2cc8dbb185d",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-sonnet-4-20250514",
          "cachedResultName": "Claude 4 Sonnet"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        540,
        180
      ],
      "id": "8b053d24-10a9-4589-b660-e784f67c6f8b",
      "name": "Anthropic Chat Model",
      "credentials": {
        "anthropicApi": {
          "id": "REDACTED",
          "name": "anthropicApi-placeholder"
        }
      }
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1.3,
      "position": [
        680,
        180
      ],
      "id": "7673fe8b-5697-467d-900c-4df017c751b8",
      "name": "Postgres Chat Memory",
      "credentials": {
        "postgres": {
          "id": "REDACTED",
          "name": "postgres-placeholder"
        }
      }
    },
    {
      "parameters": {
        "toolDescription": "Use this tool to search the web",
        "method": "POST",
        "url": "https://api.openai.com/v1/responses",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"gpt-4.1\",\n  \"tools\": [\n    {\n      \"type\": \"web_search_preview\"\n    }\n  ],\n  \"input\": \"{{ $fromAI('question') }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequestTool",
      "typeVersion": 4.2,
      "position": [
        840,
        180
      ],
      "id": "721f92c4-02bd-45d1-892b-792629397742",
      "name": "web_search",
      "credentials": {
        "openAiApi": {
          "id": "REDACTED",
          "name": "openAiApi-placeholder"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "d92ddadf-d2a6-40da-b0bc-9698cbddce5d",
              "name": "text",
              "value": "={{ $json.response }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        920,
        -60
      ],
      "id": "08c60590-7c5a-4204-ab2f-79cf59d66b34",
      "name": "Edit Fields"
    },
    {
      "parameters": {
        "code": {
          "execute": {
            "code": "// Get user input\nconst userMessage = $json.chatInput || $json.message || $json.content || \"Hi\";\nconst sessionId = $json.sessionId || \"default-session\";\n\n// Get components\nconst llmArray = await this.getInputConnectionData('ai_languageModel', 0);\nconst llm = llmArray[0];\nconst memoryArray = await this.getInputConnectionData('ai_memory', 0);\nconst memory = memoryArray[0];\nconst toolArray = await this.getInputConnectionData('ai_tool', 0);\nconst webSearchTool = toolArray[0];\n\nconst { PromptTemplate } = require('@langchain/core/prompts');\nconst { RunnableSequence } = require('@langchain/core/runnables');\nconst { JsonOutputParser } = require('@langchain/core/output_parsers');\n\n// Status tracking with detailed console logs\nconst logStatus = (status, progress, details) => {\n  const timestamp = new Date().toLocaleTimeString();\n  console.log(`[${timestamp}] ${status} (${progress}%) - ${details}`);\n};\n\n// Step 1: Research Planning\nlogStatus(\"\ud83d\udd0d STARTING RESEARCH\", 10, \"Analyzing query and creating research plan\");\nconsole.log(\"User Query:\", userMessage);\n\nconst planningPrompt = PromptTemplate.fromTemplate(\"You are a research planning expert. Break down this research query into 3-5 specific search queries.\\n\\nResearch Query: {query}\\n\\nReturn a JSON object with:\\n{{\\n  \\\"research_topic\\\": \\\"Brief title\\\",\\n  \\\"search_queries\\\": [\\\"query1\\\", \\\"query2\\\", \\\"query3\\\"],\\n  \\\"report_sections\\\": [\\\"section1\\\", \\\"section2\\\", \\\"section3\\\"]\\n}}\");\n\nconst planParser = new JsonOutputParser();\nconst planningChain = RunnableSequence.from([planningPrompt, llm, planParser]);\n\nconst researchPlan = await planningChain.invoke({ query: userMessage });\n\nlogStatus(\"\ud83d\udccb PLAN CREATED\", 20, `Created ${researchPlan.search_queries.length} search queries for: ${researchPlan.research_topic}`);\nconsole.log(\"Search Queries:\", researchPlan.search_queries);\n\n// Step 2: Execute Searches with detailed logging\nconst searchResults = [];\nconst llmWithTools = llm.bindTools([webSearchTool]);\n\nfor (let i = 0; i < researchPlan.search_queries.length; i++) {\n  const searchQuery = researchPlan.search_queries[i];\n  const searchNumber = i + 1;\n  const progress = 20 + Math.floor((searchNumber / researchPlan.search_queries.length) * 50);\n  \n  logStatus(`\ud83d\udd0d SEARCH ${searchNumber}/${researchPlan.search_queries.length}`, progress, `Executing: \"${searchQuery}\"`);\n  \n  const searchPrompt = PromptTemplate.fromTemplate(\"Research this topic: {search_query}\\nUse web_search tool to find current information.\");\n  const searchChain = RunnableSequence.from([searchPrompt, llmWithTools]);\n\n  try {\n    const searchResult = await searchChain.invoke({ search_query: searchQuery });\n    \n    if (searchResult.tool_calls && searchResult.tool_calls.length > 0) {\n      logStatus(`\ud83c\udf10 WEB SEARCH ${searchNumber}`, progress + 5, \"Retrieving data from web sources...\");\n      \n      const toolMessages = [];\n      for (const toolCall of searchResult.tool_calls) {\n        console.log(`Executing tool: ${toolCall.name} with args:`, toolCall.args);\n        const toolResult = await webSearchTool.invoke(toolCall.args);\n        \n        let searchContent = \"\";\n        if (typeof toolResult === 'string') {\n          searchContent = toolResult;\n        } else if (toolResult && toolResult.content) {\n          searchContent = toolResult.content;\n        } else if (toolResult && typeof toolResult === 'object') {\n          searchContent = JSON.stringify(toolResult);\n        }\n        \n        toolMessages.push({\n          role: \"tool\",\n          content: searchContent,\n          tool_call_id: toolCall.id\n        });\n      }\n      \n      const followUpMessages = [\n        { role: \"user\", content: searchQuery },\n        { role: \"assistant\", content: searchResult.content, tool_calls: searchResult.tool_calls },\n        ...toolMessages\n      ];\n      \n      const finalSearchResult = await llm.invoke(followUpMessages);\n      searchResults.push({\n        query: searchQuery,\n        results: finalSearchResult.content || finalSearchResult\n      });\n      \n      logStatus(`\u2705 SEARCH ${searchNumber} COMPLETE`, progress + 10, `Found ${(finalSearchResult.content || finalSearchResult).length} characters of data`);\n      \n    } else {\n      searchResults.push({\n        query: searchQuery,\n        results: searchResult.content || searchResult\n      });\n      logStatus(`\u2705 SEARCH ${searchNumber} COMPLETE`, progress + 10, \"Search completed without web tools\");\n    }\n    \n  } catch (error) {\n    searchResults.push({\n      query: searchQuery,\n      results: \"Search failed: \" + error.message\n    });\n    logStatus(`\u274c SEARCH ${searchNumber} FAILED`, progress, `Error: ${error.message}`);\n  }\n}\n\n// Step 3: Report Generation\nlogStatus(\"\ud83d\udcdd SYNTHESIZING REPORT\", 75, \"Analyzing all findings and creating comprehensive report\");\n\nconst reportPrompt = PromptTemplate.fromTemplate(\"Create a comprehensive research report.\\n\\nTopic: {topic}\\nQuery: {original_query}\\nSearch Results: {search_results}\\n\\nRequirements:\\n- Professional markdown format\\n- Executive summary\\n- Key findings with citations\\n- Conclusions and recommendations\\n- Minimum 500 words\");\n\nconst synthesisChain = RunnableSequence.from([reportPrompt, llm]);\n\nconst searchResultsText = searchResults.map((result, index) => \n  `Search ${index + 1}: ${result.query}\\nResults: ${result.results}\\n\\n`\n).join('');\n\nconsole.log(`Starting synthesis with ${searchResultsText.length} characters of search data`);\n\nconst finalReport = await synthesisChain.invoke({\n  topic: researchPlan.research_topic,\n  original_query: userMessage,\n  search_results: searchResultsText\n});\n\nlogStatus(\"\ud83d\udcc4 CREATING DOCUMENT\", 90, \"Formatting final report and preparing download\");\n\n// Document generation\nconst reportContent = finalReport.content || finalReport;\nconst timestamp = new Date().toISOString().slice(0, 10);\nconst filename = `research_report_${timestamp}.md`;\n\nconst documentContent = `# Research Report: ${researchPlan.research_topic}\n\n**Generated:** ${new Date().toLocaleDateString()}  \n**Query:** ${userMessage}  \n**Searches Conducted:** ${researchPlan.search_queries.length}\n\n---\n\n${reportContent}\n\n---\n\n## Research Methodology\n\nThis report was generated through automated research using the following search queries:\n\n${researchPlan.search_queries.map((query, index) => `${index + 1}. ${query}`).join('\\n')}\n\n**Note:** This report was generated using AI-powered research tools and web search.\n`;\n\n// Create summary\nconst summaryPrompt = PromptTemplate.fromTemplate(\"Create a brief 2-3 sentence summary of this research report for chat: {report}\");\nconst summaryChain = RunnableSequence.from([summaryPrompt, llm]);\nconst chatSummary = await summaryChain.invoke({ report: reportContent });\n\n// Save to memory\ntry {\n  await memory.saveContext(\n    { input: userMessage }, \n    { output: `Research completed: ${chatSummary.content || chatSummary}. Full report generated.` }\n  );\n  logStatus(\"\ud83d\udcbe SAVED TO MEMORY\", 95, \"Conversation history updated\");\n} catch (error) {\n  console.log(\"Memory save error:\", error);\n}\n\nlogStatus(\"\u2705 RESEARCH COMPLETE\", 100, `Generated ${documentContent.length}-character report with ${researchPlan.search_queries.length} searches`);\n\n// Return array of arrays for dual outputs\nreturn [\n  // First output array\n  [\n    {\n      json: {\n        type: \"chat_response\",\n        response: `\ud83d\udd2c **Research Complete!**\\n\\n${chatSummary.content || chatSummary}\\n\\n\ud83d\udcca **Research Summary:**\\n\u2022 Topic: ${researchPlan.research_topic}\\n\u2022 Searches: ${researchPlan.search_queries.length}\\n\u2022 Report Size: ${documentContent.length} characters\\n\u2022 Filename: ${filename}\\n\\n\ud83d\udcc4 Full report ready on second output!`,\n        sessionId: sessionId,\n        research_summary: {\n          topic: researchPlan.research_topic,\n          searches: researchPlan.search_queries.length,\n          filename: filename\n        }\n      }\n    }\n  ],\n  // Second output array\n  [\n    {\n      json: {\n        type: \"document\",\n        filename: filename,\n        full_report_text: documentContent,\n        research_metadata: {\n          topic: researchPlan.research_topic,\n          searches_conducted: researchPlan.search_queries.length,\n          sections: researchPlan.report_sections,\n          timestamp: new Date().toISOString(),\n          search_queries: researchPlan.search_queries\n        }\n      }\n    }\n  ]\n];\n"
          }
        },
        "inputs": {
          "input": [
            {
              "type": "main"
            },
            {
              "type": "ai_languageModel"
            },
            {
              "type": "ai_memory"
            },
            {
              "type": "ai_tool"
            }
          ]
        },
        "outputs": {
          "output": [
            {
              "type": "main"
            },
            {
              "type": "main"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.code",
      "typeVersion": 1,
      "position": [
        1220,
        -80
      ],
      "id": "a6d4b598-cc6d-4ce4-b829-8c084602f19b",
      "name": "LangChain Code1"
    },
    {
      "parameters": {
        "content": "## Multi Step Research Agent\nBuilding on the standard chat agent. In this agent we create an entire workflow to do research for us.\n",
        "height": 120,
        "width": 340,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1180,
        -240
      ],
      "id": "23b26ce8-ba25-4900-a2c2-f1d774e69eee",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-sonnet-4-20250514",
          "cachedResultName": "Claude 4 Sonnet"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        1160,
        160
      ],
      "id": "ff824445-7e06-4e41-af2d-a05bafb44ec4",
      "name": "Anthropic Chat Model1",
      "credentials": {
        "anthropicApi": {
          "id": "REDACTED",
          "name": "anthropicApi-placeholder"
        }
      }
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1.3,
      "position": [
        1300,
        160
      ],
      "id": "e89af9a9-713c-41e8-9e3f-e9305f159ba4",
      "name": "Postgres Chat Memory1",
      "credentials": {
        "postgres": {
          "id": "REDACTED",
          "name": "postgres-placeholder"
        }
      }
    },
    {
      "parameters": {
        "toolDescription": "Use this tool to search the web",
        "method": "POST",
        "url": "https://api.openai.com/v1/responses",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"gpt-4.1\",\n  \"tools\": [\n    {\n      \"type\": \"web_search_preview\"\n    }\n  ],\n  \"input\": \"{{ $fromAI('question') }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequestTool",
      "typeVersion": 4.2,
      "position": [
        1460,
        160
      ],
      "id": "be84f04d-c7d4-4700-82fe-231ff342bb4f",
      "name": "web_search1",
      "credentials": {
        "openAiApi": {
          "id": "REDACTED",
          "name": "openAiApi-placeholder"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "d92ddadf-d2a6-40da-b0bc-9698cbddce5d",
              "name": "text",
              "value": "={{ $json.response }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1660,
        -140
      ],
      "id": "a35c1376-d338-4d83-922d-3e596dcd39a7",
      "name": "Edit Fields1"
    },
    {
      "parameters": {
        "operation": "toText",
        "sourceProperty": "full_report_text",
        "options": {}
      },
      "type": "n8n-nodes-base.convertToFile",
      "typeVersion": 1.1,
      "position": [
        1660,
        40
      ],
      "id": "5bccb7ab-6772-432e-9043-45e7a68c9a38",
      "name": "Convert to File"
    },
    {
      "parameters": {
        "code": {
          "execute": {
            "code": "// Get user input and file data\nconst userMessage = $json.chatInput || $json.message || $json.content || \"Please analyze the uploaded document\";\nconst sessionId = $json.sessionId || \"default-session\";\n\n// Get LLM components - OpenAI for analysis, Claude for synthesis\nconst openaiArray = await this.getInputConnectionData('ai_languageModel', 0); // OpenAI GPT\nconst openaiLLM = openaiArray[0];\nconst claudeArray = await this.getInputConnectionData('ai_languageModel', 1); // Claude for synthesis\nconst claudeLLM = claudeArray[1];\n\n// Get Memory\nconst memoryArray = await this.getInputConnectionData('ai_memory', 0);\nconst memory = memoryArray[0];\n\nconst { PromptTemplate } = require('@langchain/core/prompts');\nconst { RunnableSequence } = require('@langchain/core/runnables');\nconst { JsonOutputParser } = require('@langchain/core/output_parsers');\n\n// Status tracking\nconst logStatus = (status, progress, details) => {\n  const timestamp = new Date().toLocaleTimeString();\n  console.log(`[${timestamp}] ${status} (${progress}%) - ${details}`);\n};\n\n// Step 1: Document Processing\nlogStatus(\"\ud83d\udcc4 PROCESSING DOCUMENT\", 10, \"Extracting text from uploaded file\");\n\nlet documentText = \"\";\nlet documentType = \"unknown\";\nlet filename = \"document\";\n\n// Check for binary data (LangChain Code node format)\nif (this.getInputData && this.getInputData().length > 0) {\n  const inputData = this.getInputData()[0];\n  \n  if (inputData.binary && inputData.binary.data0) {\n    try {\n      const binaryData = inputData.binary.data0;\n      filename = binaryData.fileName || \"uploaded_document\";\n      const mimeType = binaryData.mimeType || \"\";\n      const fileExtension = filename.split('.').pop()?.toLowerCase() || \"\";\n      \n      logStatus(\"\ud83d\udcc4 BINARY FILE DETECTED\", 15, `Processing: ${filename} (${mimeType})`);\n      console.log(\"Binary file info:\", { filename, mimeType, fileExtension });\n      \n      // Convert binary data to text\n      if (mimeType.includes('text') || fileExtension === 'txt' || fileExtension === 'md') {\n        // Text file - direct conversion\n        documentText = binaryData.data.toString('utf8');\n        documentType = \"text\";\n        logStatus(\"\u2705 TEXT FILE PROCESSED\", 20, `Extracted ${documentText.length} characters`);\n      } else if (mimeType.includes('pdf') || fileExtension === 'pdf') {\n        // PDF file - basic text extraction\n        documentText = binaryData.data.toString('utf8');\n        documentType = \"pdf\";\n        logStatus(\"\u26a0\ufe0f PDF BASIC EXTRACTION\", 20, `Extracted ${documentText.length} characters`);\n      } else {\n        // Other file types - attempt text extraction\n        documentText = binaryData.data.toString('utf8');\n        documentType = \"other\";\n        logStatus(\"\u2705 FILE PROCESSED\", 20, `Extracted ${documentText.length} characters`);\n      }\n      \n    } catch (error) {\n      logStatus(\"\u274c BINARY PROCESSING ERROR\", 15, `Error: ${error.message}`);\n      console.log(\"Binary processing error:\", error);\n      documentText = \"Error processing binary file data.\";\n    }\n  }\n}\n\n// Fallback: Check for files in JSON format (chat trigger format)\nif (!documentText || documentText.length < 10) {\n  if ($json.files && $json.files.length > 0) {\n    try {\n      const fileInfo = $json.files[0];\n      filename = fileInfo.fileName || \"uploaded_document\";\n      const mimeType = fileInfo.mimeType || \"\";\n      \n      logStatus(\"\ud83d\udcc4 JSON FILE DETECTED\", 15, `Processing: ${filename} (${mimeType})`);\n      \n      // Try to read file using window.fs API\n      const fileData = await window.fs.readFile(filename, { encoding: 'utf8' });\n      documentText = fileData;\n      documentType = \"text\";\n      logStatus(\"\u2705 JSON FILE PROCESSED\", 20, `Extracted ${documentText.length} characters`);\n      \n    } catch (error) {\n      logStatus(\"\u274c JSON FILE ERROR\", 15, `Error: ${error.message}`);\n      \n      // Last resort - check for direct file content\n      if ($json.files[0].fileContent) {\n        documentText = $json.files[0].fileContent;\n        filename = $json.files[0].fileName || \"fallback_document\";\n        documentType = \"fallback\";\n        logStatus(\"\ud83d\udd04 FALLBACK SUCCESS\", 20, \"Used direct file content\");\n      }\n    }\n  }\n}\n\n// Final fallback: Long text message\nif (!documentText || documentText.length < 10) {\n  if (userMessage && userMessage.length > 100) {\n    documentText = userMessage;\n    documentType = \"text_input\";\n    filename = \"text_input\";\n    logStatus(\"\ud83d\udcdd TEXT INPUT\", 15, \"Processing long text message as document\");\n  } else {\n    documentText = \"No document provided for analysis. Please upload a text file, PDF, or provide a long text message.\";\n    logStatus(\"\u26a0\ufe0f NO DOCUMENT\", 15, \"No valid document found\");\n  }\n}\n\nconsole.log(`Document extracted: ${documentText.length} characters from ${filename}`);\n\n// Step 2: Orchestrator - Parallel Analysis with OpenAI\nlogStatus(\"\ud83e\udde0 ORCHESTRATOR STARTING\", 25, \"Distributing analysis tasks to specialist workers\");\n\n// Worker 1: Summarizer\nconst summarizerPrompt = PromptTemplate.fromTemplate(`You are a professional document summarizer. Analyze this document and create a concise executive summary.\n\nDocument: {document}\n\nProvide:\n1. Main purpose/objective of the document\n2. Key points (3-5 bullet points)\n3. Critical information or decisions\n4. Overall assessment\n\nKeep it concise but comprehensive.`);\n\n// Worker 2: Categorizer  \nconst categorizerPrompt = PromptTemplate.fromTemplate(`You are a document classification expert. Analyze this document and provide detailed categorization.\n\nDocument: {document}\n\nReturn a JSON object with:\n{{\n  \"document_type\": \"contract/report/proposal/email/other\",\n  \"primary_topics\": [\"topic1\", \"topic2\", \"topic3\"],\n  \"sentiment\": \"positive/neutral/negative/mixed\",\n  \"urgency_level\": \"low/medium/high/urgent\",\n  \"audience\": \"internal/external/public/confidential\",\n  \"language_tone\": \"formal/informal/technical/casual\"\n}}\n\nOnly return valid JSON.`);\n\n// Worker 3: Analyzer\nconst analyzerPrompt = PromptTemplate.fromTemplate(`You are a strategic document analyst. Extract actionable insights and important details.\n\nDocument: {document}\n\nProvide:\n1. Key Action Items (if any)\n2. Important Dates/Deadlines\n3. Risks or Concerns\n4. Opportunities or Benefits  \n5. People/Organizations mentioned\n6. Financial information (if any)\n7. Next steps or recommendations\n\nFocus on actionable and strategic insights.`);\n\nlogStatus(\"\u26a1 PARALLEL ANALYSIS\", 30, \"Running 3 specialist analyses simultaneously\");\n\n// Create analysis chains\nconst summarizerChain = RunnableSequence.from([summarizerPrompt, openaiLLM]);\nconst categorizerChain = RunnableSequence.from([categorizerPrompt, openaiLLM, new JsonOutputParser()]);\nconst analyzerChain = RunnableSequence.from([analyzerPrompt, openaiLLM]);\n\n// Execute all analyses in parallel\nconst analysisPromises = [\n  summarizerChain.invoke({ document: documentText }),\n  categorizerChain.invoke({ document: documentText }),\n  analyzerChain.invoke({ document: documentText })\n];\n\nlet summaryResult, categoryResult, analysisResult;\n\ntry {\n  logStatus(\"\ud83d\udd04 EXECUTING WORKERS\", 40, \"OpenAI processing 3 parallel analyses...\");\n  \n  const results = await Promise.all(analysisPromises);\n  \n  summaryResult = results[0].content || results[0];\n  categoryResult = results[1]; // Already parsed JSON\n  analysisResult = results[2].content || results[2];\n  \n  logStatus(\"\u2705 WORKERS COMPLETE\", 60, \"All 3 analyses completed successfully\");\n  \n} catch (error) {\n  logStatus(\"\u274c WORKER ERROR\", 50, `Analysis error: ${error.message}`);\n  \n  // Fallback - execute sequentially\n  logStatus(\"\ud83d\udd04 FALLBACK MODE\", 55, \"Executing analyses sequentially\");\n  \n  try {\n    summaryResult = (await summarizerChain.invoke({ document: documentText })).content;\n    categoryResult = await categorizerChain.invoke({ document: documentText });\n    analysisResult = (await analyzerChain.invoke({ document: documentText })).content;\n  } catch (fallbackError) {\n    summaryResult = \"Summary analysis failed\";\n    categoryResult = { document_type: \"unknown\", error: \"Classification failed\" };\n    analysisResult = \"Strategic analysis failed\";\n  }\n}\n\n// Step 3: Synthesizer - Claude combines everything\nlogStatus(\"\ud83c\udfaf SYNTHESIZER STARTING\", 70, \"Claude synthesizing comprehensive report\");\n\nconst synthesizerPrompt = PromptTemplate.fromTemplate(`You are an expert report synthesizer. Create a comprehensive, human-readable analysis report.\n\nDOCUMENT INFO:\n- Filename: {filename}\n- Type: {doc_type}\n- Length: {doc_length} characters\n\nANALYSIS RESULTS:\n1. SUMMARY: {summary}\n\n2. CATEGORIZATION: {categorization}\n\n3. STRATEGIC ANALYSIS: {analysis}\n\nCreate a professional, well-structured report that:\n- Starts with an executive overview\n- Clearly presents all findings\n- Uses proper headings and formatting\n- Provides actionable recommendations\n- Is easy to read and understand\n\nMake it comprehensive but scannable with clear sections.`);\n\nconst synthesizerChain = RunnableSequence.from([synthesizerPrompt, claudeLLM]);\n\nlogStatus(\"\ud83e\udd16 CLAUDE SYNTHESIS\", 75, \"Generating final comprehensive report\");\n\nconst finalReport = await synthesizerChain.invoke({\n  filename: filename,\n  doc_type: documentType,\n  doc_length: documentText.length,\n  summary: summaryResult,\n  categorization: JSON.stringify(categoryResult, null, 2),\n  analysis: analysisResult\n});\n\n// Step 4: Create structured output data\nlogStatus(\"\ud83d\udcca STRUCTURING DATA\", 85, \"Preparing structured JSON output\");\n\nconst structuredOutput = {\n  document_info: {\n    filename: filename,\n    type: documentType,\n    size_characters: documentText.length,\n    processed_at: new Date().toISOString()\n  },\n  summary_analysis: {\n    executive_summary: summaryResult,\n    word_count: summaryResult.split(' ').length\n  },\n  categorization_analysis: categoryResult,\n  strategic_analysis: {\n    insights: analysisResult,\n    word_count: analysisResult.split(' ').length\n  },\n  processing_metadata: {\n    openai_workers: 3,\n    claude_synthesis: 1,\n    total_processing_time: \"estimated_seconds\",\n    parallel_execution: true\n  }\n};\n\n// Save to memory\ntry {\n  await memory.saveContext(\n    { input: `Document analysis request: ${filename}` },\n    { output: `Document analyzed successfully. Generated comprehensive report with summary, categorization, and strategic insights.` }\n  );\n  logStatus(\"\ud83d\udcbe SAVED TO MEMORY\", 90, \"Analysis session stored\");\n} catch (error) {\n  console.log(\"Memory save error:\", error);\n}\n\nlogStatus(\"\u2705 ORCHESTRATOR COMPLETE\", 100, `Successfully analyzed ${filename} with multi-LLM workflow`);\n\n// Create chat summary for immediate response\nconst chatSummary = `\ud83d\udcca **Document Analysis Complete!**\n\n**File:** ${filename} (${documentText.length} characters)\n**Type:** ${categoryResult.document_type || documentType}\n**Sentiment:** ${categoryResult.sentiment || 'analyzed'}\n\n**Quick Summary:** ${summaryResult.substring(0, 200)}...\n\n**Key Insights:** ${analysisResult.substring(0, 150)}...\n\n\ud83d\udcc4 Complete detailed report and structured data available on second output!`;\n\n// Return dual outputs - array of arrays format\nreturn [\n  // Output 1: Human-readable chat response\n  [\n    {\n      json: {\n        type: \"chat_response\",\n        response: chatSummary,\n        sessionId: sessionId,\n        quick_facts: {\n          filename: filename,\n          document_type: categoryResult.document_type || documentType,\n          sentiment: categoryResult.sentiment || \"analyzed\",\n          size: documentText.length\n        }\n      }\n    }\n  ],\n  // Output 2: Comprehensive report + structured JSON\n  [\n    {\n      json: {\n        type: \"comprehensive_analysis\",\n        full_report: finalReport.content || finalReport,\n        structured_data: structuredOutput,\n        document_metadata: {\n          filename: filename,\n          original_length: documentText.length,\n          processing_timestamp: new Date().toISOString()\n        }\n      }\n    }\n  ]\n];"
          }
        },
        "inputs": {
          "input": [
            {
              "type": "main"
            },
            {
              "type": "ai_languageModel"
            },
            {
              "type": "ai_memory"
            },
            {
              "type": "ai_tool"
            }
          ]
        },
        "outputs": {
          "output": [
            {
              "type": "main"
            },
            {
              "type": "main"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.code",
      "typeVersion": 1,
      "position": [
        2240,
        -60
      ],
      "id": "8d689fdc-9e15-4d5f-862d-b282e0710442",
      "name": "LangChain Code2"
    },
    {
      "parameters": {
        "content": "## Document Orchestrator Agent\nThis is a workflow that will process an input document against 3x seperate LLM steps",
        "height": 120,
        "width": 380,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        2120,
        -220
      ],
      "id": "6084c5fc-aee9-4326-bc40-c965efb23ac3",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-sonnet-4-20250514",
          "cachedResultName": "Claude 4 Sonnet"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        2080,
        140
      ],
      "id": "27698948-950e-45fc-86f8-13e47a0d0686",
      "name": "Anthropic Chat Model2",
      "credentials": {
        "anthropicApi": {
          "id": "REDACTED",
          "name": "anthropicApi-placeholder"
        }
      }
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1.3,
      "position": [
        2380,
        180
      ],
      "id": "50184739-27c5-4bcf-ac8d-c5300f89ff61",
      "name": "Postgres Chat Memory2",
      "credentials": {
        "postgres": {
          "id": "REDACTED",
          "name": "postgres-placeholder"
        }
      }
    },
    {
      "parameters": {
        "toolDescription": "Use this tool to search the web",
        "method": "POST",
        "url": "https://api.openai.com/v1/responses",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"gpt-4.1\",\n  \"tools\": [\n    {\n      \"type\": \"web_search_preview\"\n    }\n  ],\n  \"input\": \"{{ $fromAI('question') }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequestTool",
      "typeVersion": 4.2,
      "position": [
        2540,
        180
      ],
      "id": "c5deec3d-b23d-4a70-9341-dee7a992b91c",
      "name": "web_search2",
      "credentials": {
        "openAiApi": {
          "id": "REDACTED",
          "name": "openAiApi-placeholder"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "d92ddadf-d2a6-40da-b0bc-9698cbddce5d",
              "name": "text",
              "value": "={{ $json.response }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        2680,
        -120
      ],
      "id": "f7aa16c6-fb72-4d15-91c5-4c82d758ee58",
      "name": "Edit Fields2"
    },
    {
      "parameters": {
        "operation": "toText",
        "sourceProperty": "full_report",
        "options": {}
      },
      "type": "n8n-nodes-base.convertToFile",
      "typeVersion": 1.1,
      "position": [
        2680,
        60
      ],
      "id": "15001f54-a40d-4535-be94-3e176019e161",
      "name": "Convert to File1"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        2200,
        220
      ],
      "id": "c628e0f2-cc35-4acb-a5b3-cda1f1d589e8",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "REDACTED",
          "name": "openAiApi-placeholder"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "When chat message received": {
      "main": [
        [
          {
            "node": "LangChain Code2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "LangChain Code",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Postgres Chat Memory": {
      "ai_memory": [
        [
          {
            "node": "LangChain Code",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "web_search": {
      "ai_tool": [
        [
          {
            "node": "LangChain Code",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "LangChain Code": {
      "main": [
        [
          {
            "node": "Edit Fields",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LangChain Code1": {
      "main": [
        [
          {
            "node": "Edit Fields1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Convert to File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "LangChain Code1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Postgres Chat Memory1": {
      "ai_memory": [
        [
          {
            "node": "LangChain Code1",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "web_search1": {
      "ai_tool": [
        [
          {
            "node": "LangChain Code1",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "LangChain Code2": {
      "main": [
        [
          {
            "node": "Edit Fields2",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Convert to File1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "LangChain Code2",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Postgres Chat Memory2": {
      "ai_memory": [
        [
          {
            "node": "LangChain Code2",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "web_search2": {
      "ai_tool": [
        [
          {
            "node": "LangChain Code2",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "LangChain Code2",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "66d53db7-111f-4f24-9dde-c75cc55ce484",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "bec443f32f282145c50b8dcfc610fa7d9dd1cd11f81d464c6dad140e893c49a0"
  },
  "id": "i9Z3c2lyNz18CYhK",
  "tags": []
}