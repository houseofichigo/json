{
  "id": "H2W1Jyu1gKhpQk52",
  "meta": {
    "instanceId": "ed6d846a2fce1f660ede2e7da800724cca01dc3d0685524a3c917881b7cfcfe9",
    "templateCredsSetupCompleted": true
  },
  "name": "AI Agents - Real Time Research",
  "tags": [],
  "nodes": [
    {
      "id": "a2b142d1-90ea-42ae-9907-8bc5c4241221",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.manualChatTrigger",
      "position": [
        -200,
        0
      ],
      "parameters": {},
      "typeVersion": 1.1
    },
    {
      "id": "358ad390-f42b-411a-8c09-43ddfc406896",
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        160,
        380
      ],
      "parameters": {
        "model": "gpt-4",
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "qULV9xA6eq3tfpye",
          "name": "OpenAi - nhu.le"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "9dce7253-4994-47f5-a8db-dd7b64f28eb4",
      "name": "Window Buffer Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "position": [
        320,
        220
      ],
      "parameters": {},
      "typeVersion": 1.2
    },
    {
      "id": "7cf5d7f7-b52b-4512-ba66-7377963b8ce2",
      "name": "SerpAPI - Research",
      "type": "@n8n/n8n-nodes-langchain.toolSerpApi",
      "position": [
        500,
        220
      ],
      "parameters": {
        "options": {}
      },
      "credentials": {
        "serpApi": {
          "id": "2ZhdogyvgJsETC97",
          "name": "SerpAPI - toan.ngo"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "a590584e-ff8e-4db7-b793-cd0c43dab1b0",
      "name": "AI Agents - Real Time Research",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        260,
        0
      ],
      "parameters": {
        "options": {}
      },
      "typeVersion": 1.6
    },
    {
      "id": "aaa5e82d-a0ff-4541-936d-2ddcefe447ac",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -320,
        -300
      ],
      "parameters": {
        "color": 4,
        "width": 360,
        "height": 820,
        "content": "## 1. Start When A Chat Message Is Received\n- The workflow is triggered whenever a chat message is received (e.g., a user question, research prompt, or data request)."
      },
      "typeVersion": 1
    },
    {
      "id": "77bea2dc-9e15-4cbf-8865-945778138559",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -1120,
        -300
      ],
      "parameters": {
        "width": 740,
        "height": 1420,
        "content": "## [n8n Automation] Real-time Research AI Agent - Try It Out!\n**This workflow demonstrates how to automate live information gathering, fact-checking, and trend analysis in response to any chat message - using a powerful AI agent, memory, and a real-time search tool.**\n\nUse cases are many: This is perfect for **researchers** needing instant, up-to-date data; **support teams** providing live, accurate answers; **content creators** looking to verify facts or find hot topics; and **analysts** automating regular reports with the freshest information.\n\n## How It Works\n- The workflow is triggered whenever a chat message is received (e.g., a user question, research prompt, or data request).\n- The message is sent to the AI Agent, which follows the following steps:\n    - First, it queries **SerpAPI – Research** to gather the latest real-time information and data from the web.\n    - Next, it checks the **Window Buffer Memory** for any related past interactions or contextual information that may be useful.\n    - Finally, it sends all collected data and context to the **Google Gemini Chat Model**, which analyzes the information and generates a comprehensive, intelligent response.\n- Then, the AI Agent delivers the analyzed, up-to-date answer directly in the chat, combining live data, context, and expert analysis.\n\n## How To Set Up\n- Download and import the workflow into your n8n workspace.\n- Set up API credentials and tool access for the **AI Agent**:\n     - **Google Gemini** (for chat-based intelligence) → connected to Node **Google Gemini Chat Model**.\n     - **SerpAPI** (for real-time web and search results) → connected to Node **SerpAPI - Research**.\n     - **Window Buffer Memory** (for richer, context-aware conversations) → connected to Node Window **Buffer Memory**.\n- Open the chat in n8n and type the topic or trend you want to research.\n- Send the message and wait for the process to complete.\n- Receive the AI-powered research reply in the chat box.\n\n## Requirements\n- An **n8n** instance (self-hosted or cloud).\n- **SerpAPI** credentials for live web search and data gathering.\n- **Window Buffer Memory** configured to provide relevant conversation context in history.\n- **Google Gemini API** access to analyze collected data and generate responses.\n\n## How To Customize\n- **Choose your preferred AI model**: Replace **Google Gemini** with **OpenAI ChatGPT**, or any other chat model as preferred.\n- **Add or change memory**: Replace **Window Buffer Memory** with more advanced memory options for deeper recall.\n- **Connect your preferred chat platform**: Easily swap out the default chat integration for Telegram, Slack, or any other compatible messaging platform to trigger and interact with the workflow.\n\n## Need Help?\nIf you’d like this workflow customized, or if you’re looking to build a tailored AI Agent for your own business - please feel free to reach out to [**Agent Circle**](https://www.agentcircle.ai/). We’re always here to support and help you to bring automation ideas to life.\n\nJoin our community on different platforms for assistance, inspiration and tips from others.\n\nWebsite: https://www.agentcircle.ai/\nEtsy: https://www.etsy.com/shop/AgentCircle\nGumroad: http://agentcircle.gumroad.com/\nDiscord Global: https://discord.gg/d8SkCzKwnP\nFB Page Global: https://www.facebook.com/agentcircle/\nFB Group Global: https://www.facebook.com/groups/aiagentcircle/\nX: https://x.com/agent_circle\nYouTube: https://www.youtube.com/@agentcircle\nLinkedIn: https://www.linkedin.com/company/agentcircle\n\n\n"
      },
      "typeVersion": 1
    },
    {
      "id": "b53905ce-0343-4713-9267-6f9b280a5be8",
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        60,
        -300
      ],
      "parameters": {
        "color": 4,
        "width": 660,
        "height": 820,
        "content": "## 2. Process The Request & Return Response\n- The message is sent to the AI Agent, which follows the following steps:\n    - First, it queries **SerpAPI – Research** to gather the latest real-time information and data from the web.\n    - Next, it checks the **Window Buffer Memory** for any related past interactions or contextual information that may be useful.\n    - Finally, it sends all collected data and context to the **Google Gemini Chat Model**, which analyzes the information and generates a comprehensive, intelligent response.\n- Then, the AI Agent delivers the analyzed, up-to-date answer directly in the chat, combining live data, context, and expert analysis."
      },
      "typeVersion": 1
    },
    {
      "id": "b3e0c845-deaa-4147-940b-92efb4ef9475",
      "name": "Google Gemini Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "position": [
        160,
        220
      ],
      "parameters": {
        "options": {},
        "modelName": "models/gemini-2.0-flash"
      },
      "credentials": {
        "googlePalmApi": {
          "id": "AlDwotqhFT4EfJXQ",
          "name": "Google Gemini(PaLM) Api - toan.ngo"
        }
      },
      "typeVersion": 1
    }
  ],
  "active": false,
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "404f0c7d-c796-40c6-b0e6-7944f1223081",
  "connections": {
    "OpenAI Chat Model": {
      "ai_languageModel": [
        []
      ]
    },
    "SerpAPI - Research": {
      "ai_tool": [
        [
          {
            "node": "AI Agents - Real Time Research",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Window Buffer Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agents - Real Time Research",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agents - Real Time Research",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "AI Agents - Real Time Research",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  }
}